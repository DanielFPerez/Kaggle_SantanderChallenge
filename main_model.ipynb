{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "Hello, this notebook will gruide you through building a classifier proposing one possible solution to the santander customer satisfaction problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Lets start by importing dependencies\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# IMPORT\n",
    "# ===============================================================\n",
    "import include.preprocess as preprocess\n",
    "import include.printAssistant as printAssistant\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "plt.interactive(False)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Now its time to define the number of hyperparameters over which out model is going to be trained. Following options are available: \n",
    "<ul>\n",
    "    <li>n_pca_dimension_cases:  number of possible dimensions when applying PCA (possibly + 1 empirical value, see below)</li>\n",
    "    <li>n_n_estimators: number of possible \"n_estimators\", i.e. number of used trees, for a random forest model (possibly + 1 empirical value, see below)</li>\n",
    "    <li>n_max_depth: maximum depth of a tree for a random forest classifier (possibly + 1 empirical value, see below)\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca_dimension_cases = 2\n",
    "n_n_estimators = 2\n",
    "n_max_depth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Other values include lists, whose elements have to be changed manually. The possible values are found in the module \"include/preprocess.py\". These lists include:\n",
    "<ul>\n",
    "    <li>df_filter_cases: different variants of feature selection for training the model</li>\n",
    "    <li>norm_case_cases: possible data normalization alternatives</li>\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cases extracting different features from the available data\n",
    "# See include/preprocess.py for more df_filter_cases options\n",
    "df_filter_cases = ['low-valued-plus', 'middle-valued-plus', 'high-valued']\n",
    "\n",
    "# Set normalization case implemented\n",
    "norm_case_cases = ['mean', 'minmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note</b>: select previous variables according to the computational power available.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Lets finish setting up the variables for performing the hyper-parameter search\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of PCA components to try out\n",
    "# Choose 3 random values between 3 dimensions and 20 dimensions\n",
    "pca_dimension_cases = np.random.randint(low=3, high=18, size=n_pca_dimension_cases)\n",
    "# Append value 15 as was the highest performing PCA dimension during manual exploration\n",
    "if 15 not in pca_dimension_cases:\n",
    "    pca_dimension_cases = np.append(pca_dimension_cases, 15)\n",
    "\n",
    "# Parameters for the random forest\n",
    "# Number of trees in the RF\n",
    "n_estimators = np.random.randint(2, 15, size=n_n_estimators)\n",
    "if 10 not in n_estimators:\n",
    "    n_estimators = np.append(n_estimators, 10)\n",
    "# Max depth of tree\n",
    "max_depth = np.random.randint(5, 40, size=n_max_depth)\n",
    "if 30 not in n_estimators:\n",
    "    max_depth = np.append(max_depth, 30)\n",
    "\n",
    "rf_grid = [(i, j) for i in n_estimators.tolist() for j in max_depth.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Lets see how many possible cases are we going to evaluate:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of  108  cases will be evaluated.\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "n_tot_cases = n_tot_cases = len(norm_case_cases) * len(df_filter_cases) * pca_dimension_cases.shape[0] * n_estimators.shape[0] * max_depth.shape[0]\n",
    "print(\"A total of \", n_tot_cases, \" cases will be evaluated.\\n\")\n",
    "print(n_estimators.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Now we define variables for logging and saving the optimal model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for storing best performance tree in the test set\n",
    "rf_winner = {\"logger_index\": None,\n",
    "             \"filter_case\": None,\n",
    "             \"norm_case\": None,\n",
    "             \"pca_dim\": 0,\n",
    "             \"n_trees\": 0,\n",
    "             \"tree_depth\": 0,\n",
    "             \"auc_val\": 0.0,\n",
    "             \"auc_test\": 0.0,\n",
    "             \"rf_object\": None}\n",
    "roc_auc_test_tracker = 0.0\n",
    "roc_auc_val_tracker = 0.0\n",
    "\n",
    "# Pandas dataFrame for logging\n",
    "out_cols = [\"filter_case\", \"norm_case\", \"pca_dim\", \"n_trees\", \"tree_depth\", \"cv_mean_auc\", \"test_auc\", \"image_path\"]\n",
    "pd_logger = pd.DataFrame(columns=out_cols)\n",
    "logger_index = 0\n",
    "\n",
    "# Directory for saving winner\n",
    "out_path_winner = \"./data/output/\"\n",
    "\n",
    "# Directory for saving logger and plots\n",
    "out_path_log = \"./data/output/log/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Search the optimal model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum cv mean auc found:  0.8275490886631116  at logger index:  0\n",
      "New best AUC over test set found:  0.786878509793179 at logger index:  0\n",
      "################################ Model iteration  0  finished ################################ \n",
      "Maximum cv mean auc found:  0.8583272197963242  at logger index:  1\n",
      "################################ Model iteration  1  finished ################################ \n",
      "################################ Model iteration  2  finished ################################ \n",
      "################################ Model iteration  3  finished ################################ \n",
      "################################ Model iteration  4  finished ################################ \n",
      "Maximum cv mean auc found:  0.8590923720300145  at logger index:  5\n",
      "################################ Model iteration  5  finished ################################ \n",
      "New best AUC over test set found:  0.7976766483087694 at logger index:  6\n",
      "################################ Model iteration  6  finished ################################ \n",
      "################################ Model iteration  7  finished ################################ \n",
      "################################ Model iteration  8  finished ################################ \n",
      "################################ Model iteration  9  finished ################################ \n",
      "################################ Model iteration  10  finished ################################ \n",
      "################################ Model iteration  11  finished ################################ \n",
      "################################ Model iteration  12  finished ################################ \n",
      "################################ Model iteration  13  finished ################################ \n",
      "################################ Model iteration  14  finished ################################ \n",
      "################################ Model iteration  15  finished ################################ \n",
      "Maximum cv mean auc found:  0.8592955402377284  at logger index:  16\n",
      "################################ Model iteration  16  finished ################################ \n",
      "################################ Model iteration  17  finished ################################ \n",
      "New best AUC over test set found:  0.8058421433190102 at logger index:  18\n",
      "################################ Model iteration  18  finished ################################ \n",
      "Maximum cv mean auc found:  0.8626511424931356  at logger index:  19\n",
      "################################ Model iteration  19  finished ################################ \n",
      "Maximum cv mean auc found:  0.8633598898759831  at logger index:  20\n",
      "################################ Model iteration  20  finished ################################ \n",
      "New best AUC over test set found:  0.8076857445914887 at logger index:  21\n",
      "################################ Model iteration  21  finished ################################ \n",
      "################################ Model iteration  22  finished ################################ \n",
      "Maximum cv mean auc found:  0.8644155765363196  at logger index:  23\n",
      "################################ Model iteration  23  finished ################################ \n",
      "################################ Model iteration  24  finished ################################ \n",
      "################################ Model iteration  25  finished ################################ \n",
      "################################ Model iteration  26  finished ################################ \n",
      "################################ Model iteration  27  finished ################################ \n",
      "################################ Model iteration  28  finished ################################ \n",
      "################################ Model iteration  29  finished ################################ \n",
      "################################ Model iteration  30  finished ################################ \n",
      "Maximum cv mean auc found:  0.8660960614980787  at logger index:  31\n",
      "################################ Model iteration  31  finished ################################ \n",
      "Maximum cv mean auc found:  0.8661543913974551  at logger index:  32\n",
      "################################ Model iteration  32  finished ################################ \n",
      "################################ Model iteration  33  finished ################################ \n",
      "################################ Model iteration  34  finished ################################ \n",
      "Maximum cv mean auc found:  0.8663490949564754  at logger index:  35\n",
      "################################ Model iteration  35  finished ################################ \n",
      "################################ Model iteration  36  finished ################################ \n",
      "################################ Model iteration  37  finished ################################ \n",
      "################################ Model iteration  38  finished ################################ \n",
      "################################ Model iteration  39  finished ################################ \n",
      "################################ Model iteration  40  finished ################################ \n",
      "################################ Model iteration  41  finished ################################ \n",
      "################################ Model iteration  42  finished ################################ \n",
      "################################ Model iteration  43  finished ################################ \n",
      "################################ Model iteration  44  finished ################################ \n",
      "################################ Model iteration  45  finished ################################ \n",
      "################################ Model iteration  46  finished ################################ \n",
      "################################ Model iteration  47  finished ################################ \n",
      "################################ Model iteration  48  finished ################################ \n",
      "################################ Model iteration  49  finished ################################ \n",
      "################################ Model iteration  50  finished ################################ \n",
      "################################ Model iteration  51  finished ################################ \n",
      "################################ Model iteration  52  finished ################################ \n",
      "################################ Model iteration  53  finished ################################ \n",
      "################################ Model iteration  54  finished ################################ \n",
      "################################ Model iteration  55  finished ################################ \n",
      "################################ Model iteration  56  finished ################################ \n",
      "################################ Model iteration  57  finished ################################ \n",
      "################################ Model iteration  58  finished ################################ \n",
      "################################ Model iteration  59  finished ################################ \n",
      "################################ Model iteration  60  finished ################################ \n",
      "################################ Model iteration  61  finished ################################ \n",
      "################################ Model iteration  62  finished ################################ \n",
      "################################ Model iteration  63  finished ################################ \n",
      "################################ Model iteration  64  finished ################################ \n",
      "################################ Model iteration  65  finished ################################ \n",
      "################################ Model iteration  66  finished ################################ \n",
      "################################ Model iteration  67  finished ################################ \n",
      "################################ Model iteration  68  finished ################################ \n",
      "################################ Model iteration  69  finished ################################ \n",
      "################################ Model iteration  70  finished ################################ \n",
      "################################ Model iteration  71  finished ################################ \n",
      "################################ Model iteration  72  finished ################################ \n",
      "################################ Model iteration  73  finished ################################ \n",
      "################################ Model iteration  74  finished ################################ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################ Model iteration  75  finished ################################ \n",
      "################################ Model iteration  76  finished ################################ \n",
      "################################ Model iteration  77  finished ################################ \n",
      "################################ Model iteration  78  finished ################################ \n",
      "################################ Model iteration  79  finished ################################ \n",
      "################################ Model iteration  80  finished ################################ \n",
      "################################ Model iteration  81  finished ################################ \n",
      "################################ Model iteration  82  finished ################################ \n",
      "################################ Model iteration  83  finished ################################ \n",
      "################################ Model iteration  84  finished ################################ \n",
      "################################ Model iteration  85  finished ################################ \n",
      "################################ Model iteration  86  finished ################################ \n",
      "################################ Model iteration  87  finished ################################ \n",
      "################################ Model iteration  88  finished ################################ \n",
      "################################ Model iteration  89  finished ################################ \n",
      "################################ Model iteration  90  finished ################################ \n",
      "################################ Model iteration  91  finished ################################ \n",
      "################################ Model iteration  92  finished ################################ \n",
      "################################ Model iteration  93  finished ################################ \n",
      "################################ Model iteration  94  finished ################################ \n",
      "################################ Model iteration  95  finished ################################ \n",
      "################################ Model iteration  96  finished ################################ \n",
      "################################ Model iteration  97  finished ################################ \n",
      "################################ Model iteration  98  finished ################################ \n",
      "################################ Model iteration  99  finished ################################ \n",
      "################################ Model iteration  100  finished ################################ \n",
      "################################ Model iteration  101  finished ################################ \n",
      "################################ Model iteration  102  finished ################################ \n",
      "################################ Model iteration  103  finished ################################ \n",
      "################################ Model iteration  104  finished ################################ \n",
      "################################ Model iteration  105  finished ################################ \n",
      "################################ Model iteration  106  finished ################################ \n",
      "################################ Model iteration  107  finished ################################ \n",
      "\n",
      "\n",
      "Finding the optimal model took approximately 42.61  minutes\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Build-Train-Test\n",
    "# ===============================================================\n",
    "t_start = time.time()\n",
    "\n",
    "# Load a pre-cleaned the dataset\n",
    "df_raw = preprocess.get_raw_cleaned_data()\n",
    "\n",
    "# Iterate over filter cases\n",
    "for feature_filter in df_filter_cases:\n",
    "    # Subtract a subset of the feature columns from filtered dataset\n",
    "    df_filtered = preprocess.filter_dataframe(dataframe=df_raw, filter_case=feature_filter)\n",
    "\n",
    "    for norm_case in norm_case_cases:\n",
    "        df_normalized = preprocess.norm_transform_dataframe(dataframe=df_filtered, norm_case=norm_case,\n",
    "                                                            scale_factor=1000)\n",
    "\n",
    "        for pca_dim in pca_dimension_cases:\n",
    "            # Apply PCA\n",
    "            df_pca = preprocess.apply_pca(dataframe=df_normalized, dimensions=pca_dim)\n",
    "\n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = preprocess.split_datagram_test_train(df_pca,\n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "            # Perform oversampling\n",
    "            X_smot, y_smot = preprocess.perform_smote(X_train, y_train)\n",
    "\n",
    "            for (estim, depth) in rf_grid:\n",
    "                cv = StratifiedKFold(n_splits=8)\n",
    "                classifier = RandomForestClassifier(n_estimators=estim, max_depth=depth, min_samples_split=600)\n",
    "\n",
    "                tprs = []\n",
    "                aucs = []\n",
    "                mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "                cv_tracker = 0\n",
    "                for train, test in cv.split(X_smot, y_smot):\n",
    "                    classifier.fit(X_smot[train], y_smot[train])\n",
    "                    probabilities = classifier.predict_proba(X_smot[test])\n",
    "                    # Compute ROC curve and area the curve\n",
    "                    fpr, tpr, thresholds = roc_curve(y_smot[test], probabilities[:,1])\n",
    "                    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "                    tprs[-1][0] = 0.0\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    aucs.append(roc_auc)\n",
    "                    # Add result of cv fold to the final auc plot\n",
    "                    printAssistant.subplot_rocauc_cvfold(fpr, tpr, roc_auc, cv_tracker)\n",
    "                    # Increment cv tracker\n",
    "                    cv_tracker += 1\n",
    "\n",
    "                mean_tpr = np.mean(tprs, axis=0)\n",
    "                mean_auc = auc(mean_fpr, mean_tpr)\n",
    "                std_auc = np.std(aucs)\n",
    "                std_tpr = np.std(tprs, axis=0)\n",
    "\n",
    "                # Evaluate on test set\n",
    "                probs_test = classifier.predict_proba(X_test)\n",
    "                fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probs_test[:, 1])\n",
    "                roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "                avoid_cv_test_overlap = True\n",
    "\n",
    "                # Log result if new best AUC over x-validation found\n",
    "                if mean_auc > roc_auc_val_tracker:\n",
    "                    roc_auc_val_tracker = mean_auc\n",
    "                    print(\"Maximum cv mean auc found: \", mean_auc, \" at logger index: \", logger_index)\n",
    "                    printAssistant.plot_total_rocauc(mean_tpr, mean_auc, std_auc, std_tpr, mean_fpr)\n",
    "                    img_path = out_path_log + \"cv_roc_plot_\" + str(logger_index) + \".png\"\n",
    "                    printAssistant.save_auc_roc_plot(img_path)\n",
    "                    avoid_cv_test_overlap = False\n",
    "                    pd_logger.loc[logger_index] = {\"filter_case\": feature_filter,\n",
    "                                                   \"norm_case\": norm_case,\n",
    "                                                   \"pca_dim\": pca_dim,\n",
    "                                                   \"n_trees\": estim,\n",
    "                                                   \"tree_depth\": depth,\n",
    "                                                   \"cv_mean_auc\": mean_auc,\n",
    "                                                   \"test_auc\": roc_auc_test,\n",
    "                                                   \"image_path\": img_path}\n",
    "                    # Close plot to be able to plot after each iteration\n",
    "                    if roc_auc_test < roc_auc_test_tracker:\n",
    "                        printAssistant.close_plot()\n",
    "\n",
    "                # Log winner rf if test performance achieved\n",
    "                if roc_auc_test > roc_auc_test_tracker:\n",
    "                    roc_auc_test_tracker = roc_auc_test\n",
    "                    rf_winner[\"logger_index\"] = logger_index\n",
    "                    rf_winner[\"filter_case\"] = feature_filter\n",
    "                    rf_winner[\"pca_dim\"] = pca_dim\n",
    "                    rf_winner[\"n_trees\"] = estim\n",
    "                    rf_winner[\"tree_depth\"] = depth\n",
    "                    rf_winner[\"auc_val\"] = mean_auc\n",
    "                    rf_winner[\"auc_test\"] = roc_auc_test\n",
    "                    rf_winner[\"rf_object\"] = classifier\n",
    "                    print(\"New best AUC over test set found: \", roc_auc_test, \"at logger index: \", logger_index)\n",
    "                    # Add case to log file\n",
    "                    if avoid_cv_test_overlap:\n",
    "                        printAssistant.plot_total_rocauc(mean_tpr, mean_auc, std_auc, std_tpr, mean_fpr)\n",
    "                        img_path = out_path_log + \"cv_roc_plot_\" + str(logger_index) + \".png\"\n",
    "                        printAssistant.save_auc_roc_plot(img_path)\n",
    "                    pd_logger.loc[logger_index] = {\"filter_case\": feature_filter,\n",
    "                                                   \"norm_case\": norm_case,\n",
    "                                                   \"pca_dim\": pca_dim,\n",
    "                                                   \"n_trees\": estim,\n",
    "                                                   \"tree_depth\": depth,\n",
    "                                                   \"cv_mean_auc\": mean_auc,\n",
    "                                                   \"test_auc\": roc_auc_test,\n",
    "                                                   \"image_path\": img_path}\n",
    "                    # Save/overwrite image of rf_winner\n",
    "                    printAssistant.save_auc_roc_plot(out_path_winner+\"rf_winner.png\")\n",
    "                    # Close plot to be able to plot after each iteration\n",
    "                    printAssistant.close_plot()\n",
    "                printAssistant.close_plot()\n",
    "                # Increment the logger index\n",
    "                print(\"################################ Model iteration \", logger_index, \" finished ################################ \")\n",
    "                logger_index += 1\n",
    "\n",
    "print(\"\\n\\nFinding the optimal model took approximately\", np.around((time.time()-t_start)/60, decimals=2), \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC on the test set achieved:  80.77 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Best AUC on the test set achieved: \", np.around(rf_winner[\"auc_test\"]*100, decimals=2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test score: \t 80.77 %\n",
      "AUC CV score: \t\t 83.31 %\n",
      "Filter case: \t\t low-valued-plus\n",
      "PCA dimensions: \t 11\n",
      "Number of trees: \t 11\n",
      "Depth of the tree: \t 7\n"
     ]
    }
   ],
   "source": [
    "# Display values from rf_winner\n",
    "print(\"AUC test score: \\t\", np.around(rf_winner[\"auc_test\"]*100, decimals=2), \"%\")\n",
    "print(\"AUC CV score: \\t\\t\", np.around(rf_winner[\"auc_val\"]*100, decimals=2), \"%\")\n",
    "print(\"Filter case: \\t\\t\", rf_winner[\"filter_case\"])\n",
    "print(\"PCA dimensions: \\t\", rf_winner[\"pca_dim\"])\n",
    "print(\"Number of trees: \\t\", rf_winner[\"n_trees\"])\n",
    "print(\"Depth of the tree: \\t\", rf_winner[\"tree_depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Save log file and optimal results\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save log table\n",
    "pd_logger.to_csv(out_path_log+\"log.csv\")\n",
    "\n",
    "# Save winner model\n",
    "pickle_out = out_path_winner+\"rf_winner.pkl\"\n",
    "with open(pickle_out, 'wb') as file:\n",
    "    pickle.dump(rf_winner, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Model has been saved in \"./data/output/rf_winner.pkl\". \n",
    "Save locally or move the model to \"./data/output/log_backup\" before running the script again in order to not lose the results here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" To use/migrate the RF trained, load it in another script like: \"\"\"\n",
    "# import pickle\n",
    "# import os\n",
    "# target = \"./data/output/rf_winner.pkl\"\n",
    "# model_results = {}\n",
    "# if os.path.getsize(target) > 0:\n",
    "#     with open(target, \"rb\") as f:\n",
    "#         unpickler = pickle.Unpickler(f)\n",
    "#         model_results = unpickler.load()\n",
    "# # Classifier\n",
    "# rf_classifier = model_results[\"rf_object\"]\n",
    "# # Use classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
