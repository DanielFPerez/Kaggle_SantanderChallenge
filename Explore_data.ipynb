{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "Notebook for providing insights about the available training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================\n",
    "# Import section\n",
    "# ============================================================================================================\n",
    "import autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================\n",
    "# Load Data\n",
    "# ============================================================================================================\n",
    "\n",
    "# Get Working Directory \n",
    "src_dir = os.getcwd()\n",
    "print(\"Working directory: \\t\\t\", src_dir)\n",
    "\n",
    "# Data directory\n",
    "data_dir = os.path.join(src_dir, \"data\")\n",
    "print(\"Path for data files: \\t\\t\", data_dir)\n",
    "\n",
    "# Source path for training data\n",
    "train_data_path = os.path.join(data_dir, \"train.csv\")\n",
    "print(\"Path to trainign data file: \\t\", train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data as dataframe\n",
    "pd_train = pd.read_csv(train_data_path)\n",
    "\n",
    "# Display first 5 rows of dataframe\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know from the problem decrition that: \n",
    "# - Column \"ID\" refers to a customer\n",
    "# - Column \"TARGET\" refers to the values to be predicted\n",
    "# The rest of the columns correspond to the features\n",
    "\n",
    "# List of strings corresponding to features column names\n",
    "l_feat_cols =  [x for x in pd_train.columns if not x in ['ID','TARGET']]\n",
    "\n",
    "# Number of training samples\n",
    "n_samples = pd_train.shape[0]\n",
    "\n",
    "print(\"\\nNumber of training samples available: \", n_samples)\n",
    "print(\"Number of feature columns: \", len(l_feat_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We note note that there are a lot of possible features to use and that we have over 70k data samples available. \n",
    "\n",
    "Lets see how our binary classes present in the dataset are divided.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify distribution of classes\n",
    "target_vals = pd.DataFrame(pd_train.TARGET.value_counts())\n",
    "target_vals[\"Prozent\"] = target_vals.TARGET / n_samples\n",
    "\n",
    "# Visualize values dataframe\n",
    "display(target_vals)\n",
    "\n",
    "print(\"Percentage of Satisfied customers: \\t\", np.around(target_vals.Prozent[0]*100, decimals=2), \"%\")\n",
    "print(\"Percentage of Unsatisfied customers: \\t\", np.around(target_vals.Prozent[1]*100, decimals=2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This shows that the classes are highly imbalanced. This might represent a risk when training a model, as the model may infere that always predicting class \"0\" would be a good approxiamte.\n",
    "\n",
    "If evaluating the performance of the model is always based on the accuracy, then we might get results similar to 90% even if the model fails to identify class \"1\". So choosing the AUC of the ROC curve is a better performance metric.\n",
    "\n",
    "As collecting more data is not an option, it might be helpful to oversample the minority class or undersample the majority class. \n",
    "\n",
    "Before proceeding, lets try to analyze more the features. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "pd_train_features = pd_train[l_feat_cols]\n",
    "pd_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns only containing one, two or 3 possible values \n",
    "single_valued_column = []\n",
    "doubled_valued_column = []\n",
    "tripple_valued_column = []\n",
    "\n",
    "for col in l_feat_cols:\n",
    "    print(\"Value counts for column: \", col )\n",
    "    temp_counts = pd.DataFrame(pd_train_features[col].value_counts())\n",
    "    display(temp_counts)\n",
    "    \n",
    "    n_values = temp_counts.shape[0]\n",
    "    \n",
    "    if n_values == 1:\n",
    "        single_valued_column.append(col)\n",
    "    elif n_values == 2:\n",
    "        doubled_valued_column.append(col)\n",
    "    elif n_values == 3:\n",
    "        tripple_valued_column.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from previous examination\n",
    "print(\"# of columns with 1 value:  \", len(single_valued_column))\n",
    "print(\"# of columns with 2 values: \", len(doubled_valued_column))\n",
    "print(\"# of columns with 3 values: \", len(tripple_valued_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We are not interested in features which are constant along all training samples (single_valued_column), as these do not contribute to identifying the hyperplanes among the feature space.\n",
    "\n",
    "Therefore, we bump the single_valued_columns from our training dataset\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train_filtered = pd_train.drop(single_valued_column, axis=1)\n",
    "pd_train_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
